{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle as pk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding,Input,BatchNormalization,Dense,Bidirectional,LSTM,Dropout\n",
    "from keras.callbacks import History ,ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.merge import add, dot, concatenate, multiply, average\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LabelsMapping = {'Other': 0,\n",
    "                 'Message-Topic(e1,e2)': 1, 'Message-Topic(e2,e1)': 2,\n",
    "                 'Product-Producer(e1,e2)': 3, 'Product-Producer(e2,e1)': 4,\n",
    "                 'Instrument-Agency(e1,e2)': 5, 'Instrument-Agency(e2,e1)': 6,\n",
    "                 'Entity-Destination(e1,e2)': 7, 'Entity-Destination(e2,e1)': 8,\n",
    "                 'Cause-Effect(e1,e2)': 9, 'Cause-Effect(e2,e1)': 10,\n",
    "                 'Component-Whole(e1,e2)': 11, 'Component-Whole(e2,e1)': 12,\n",
    "                 'Entity-Origin(e1,e2)': 13, 'Entity-Origin(e2,e1)': 14,\n",
    "                 'Member-Collection(e1,e2)': 15, 'Member-Collection(e2,e1)': 16,\n",
    "                 'Content-Container(e1,e2)': 17, 'Content-Container(e2,e1)': 18}\n",
    "\n",
    "def _shuffle(X, feature1, feature2, y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "    return (X[randomize], feature1[randomize], feature2[randomize], y[randomize])\n",
    "\n",
    "def load_data(FILE_Path):\n",
    "    otuput_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    with open(FILE_Path, \"r\") as f:\n",
    "        train_tmp = f.read().split(\"\\n\\n\")[:-1]\n",
    "        for sample in train_tmp:\n",
    "            sentence = re.split('\\t|\\n', sample)[1].replace('\\\"',\"\").replace(\".\",\"\").replace(\",\",\"\")\\\n",
    "            .replace(\"?\",\"\").replace(\"!\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"\\'s\",\"\")\\\n",
    "            .replace(\"\\'ve\",\"\").replace(\"\\'t\",\"\").replace(\"\\'re\",\"\").replace(\"\\'d\",\"\").replace(\"\\'ll\",\"\")\n",
    "            answer = re.split('\\t|\\n', sample)[2]\n",
    "            soup = BeautifulSoup(sentence,\"lxml\")\n",
    "\n",
    "            e1 = str(soup.find('e1'))[4:-5]\n",
    "            e2 = str(soup.find('e2'))[4:-5]\n",
    "            word_list = sentence.split(\" \")\n",
    "            for word in word_list:\n",
    "                if \"</e1>\" in word:\n",
    "                    a = word\n",
    "                if \"</e2>\" in word:\n",
    "                    b = word\n",
    "            p1 = word_list.index(a)\n",
    "            p2 = word_list.index(b)\n",
    "            sentence = sentence.replace(\"<e1>\",\"\").replace(\"</e1>\",\"\").replace(\"<e2>\",\"\").\\\n",
    "            replace(\"</e2>\",\"\")\n",
    "#             sentence = [lemmatizer.lemmatize(word, pos='v') for word in sentence.split(\" \")]\n",
    "#             sentence = \" \".join(sentence)\n",
    "            otuput_sent.append((sentence,e1,e2,p1,p2,answer))\n",
    "    return otuput_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training instances: 8000\n",
      "number of testing instances: 2717\n"
     ]
    }
   ],
   "source": [
    "train_instance = load_data('./data/TRAIN_FILE.txt')\n",
    "test_instance = load_data('./data/TEST_FILE_FULL.txt')\n",
    "# sentence_list = train_sentence + test_sentence\n",
    "print(\"number of training instances:\", len(train_instance))\n",
    "print(\"number of testing instances:\", len(test_instance))\n",
    "# tuple format: (text, e1, e2, pos1, pos2, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "num_classes = 19\n",
    "train_text = []\n",
    "for instance in train_instance:\n",
    "    p1 = instance[3]\n",
    "    p2 = instance[4]\n",
    "    split_sentence = instance[0].split(\" \")\n",
    "    p1_mod = max(0,p1-3)\n",
    "    p2_mod = min(len(split_sentence), p2+3)\n",
    "    prune_text = \" \".join(split_sentence[p1:p2+1])\n",
    "    train_text.append(prune_text)\n",
    "\n",
    "train_label = [LabelsMapping[ele[5]] for ele in train_instance]\n",
    "train_label = dense_to_one_hot(np.array(train_label), 19)\n",
    "\n",
    "test_text = []\n",
    "for instance in test_instance:\n",
    "    p1 = instance[3]\n",
    "    p2 = instance[4]\n",
    "    split_sentence = instance[0].split(\" \")\n",
    "    p1_mod = max(0,p1-3)\n",
    "    p2_mod = min(len(split_sentence), p2+3)\n",
    "    prune_text = \" \".join(split_sentence[p1:p2+1])\n",
    "    test_text.append(prune_text)\n",
    "    \n",
    "test_label = [LabelsMapping[ele[5]] for ele in test_instance]\n",
    "test_label = dense_to_one_hot(np.array(test_label), 19)\n",
    "\n",
    "total_text = train_text + test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mut_ancestors_list = np.load(\"./features/train_mut_ancestors_list.npy\")\n",
    "test_mut_ancestors_list = np.load(\"./features/test_mut_ancestors_list.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dep_list = np.load(\"./features/train_dep_list.npy\")\n",
    "test_dep_list = np.load(\"./features/test_dep_list.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11518 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=25000,lower=True,split=' ',char_level=False)\n",
    "tokenizer.fit_on_texts(total_text)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 33\n"
     ]
    }
   ],
   "source": [
    "train_sentence_seq = tokenizer.texts_to_sequences(train_text)\n",
    "test_sentence_seq = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "max_length = np.max([len(i) for i in train_sentence_seq+test_sentence_seq])\n",
    "print(\"max length:\", max_length)\n",
    "\n",
    "x_train_seq = sequence.pad_sequences(train_sentence_seq, maxlen=max_length)\n",
    "x_test_seq = sequence.pad_sequences(test_sentence_seq, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# download pre-trained word vector from \"https://nlp.stanford.edu/projects/glove/\"\n",
    "tmp_file = get_tmpfile(\"/home/thtang/LifeLog/data/glove_pretrained/gensim_crawl_300d.txt\")\n",
    "\n",
    "w2vModel = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "embedding_size = 300\n",
    "num_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros((num_words, embedding_size))\n",
    "oov = 0\n",
    "for word, i in word_index.items():\n",
    "    if word in w2vModel.wv.vocab:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = w2vModel[word]\n",
    "    else:\n",
    "        oov+=1\n",
    "print(\"OOV:\",oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Embedding, Input,InputLayer,BatchNormalization, Dense, Bidirectional,LSTM,Dropout,GRU,Activation\n",
    "from keras import backend as K\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "def train_BiLSTM(x_train, ancestor_train, dep_train, y_train, \n",
    "                 x_val, ancestor_val, dep_val, y_val,\n",
    "                 embedding_matrix, max_length, max_features):\n",
    "    embedding_size = 300\n",
    "    batch_size = 64\n",
    "    epochs = 50\n",
    "    embedding_layer = Embedding(max_features,output_dim= embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "    sequence_input = Input(shape=(max_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    lstm0 = Bidirectional(LSTM(256,activation=\"tanh\",dropout=0.2,return_sequences = True,\n",
    "                kernel_initializer='he_uniform'))(embedded_sequences)\n",
    "    lstm1 = Bidirectional(LSTM(128,activation=\"tanh\",dropout=0.2,return_sequences = True,\n",
    "                kernel_initializer='he_uniform'))(lstm0)\n",
    "    lstm2 = Bidirectional(LSTM(64,activation=\"tanh\",dropout=0.2,return_sequences = False,\n",
    "                kernel_initializer='he_uniform'))(lstm1)\n",
    "    bn1 = BatchNormalization()(lstm2)\n",
    "    \n",
    "    # other feature inputs \n",
    "    ancestor_input = Input(shape=(2,))\n",
    "    ancestor_feature = Dense(64, activation=swish)(ancestor_input)\n",
    "    \n",
    "    \n",
    "    dep_input = Input(shape=(34,))\n",
    "    dep_feature = Dense(128, activation=swish)(dep_input)\n",
    "    \n",
    "    combine_feature = concatenate([bn1, ancestor_feature, dep_feature])\n",
    "    dense1 = Dense(64, activation=swish)(combine_feature)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(32, activation=swish)(dropout1)\n",
    "    dropout2 = Dropout(0.5)(dense2)\n",
    "    preds = Dense(19, activation='softmax')(dropout2)\n",
    "    model = Model([sequence_input, ancestor_input, dep_input], preds)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    filepath = \"models/BiLSTM_3.hdf5\" \n",
    "    checkpoint = ModelCheckpoint(filepath,monitor='val_acc',save_best_only=True)\n",
    "    history = History()\n",
    "    callbacks_list = [checkpoint, history]\n",
    "    \n",
    "    history = model.fit([x_train, ancestor_train, dep_train], y_train, \n",
    "                        validation_data=([x_val, ancestor_val, dep_val], y_val), \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        callbacks=callbacks_list)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2717 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 2.4330 - acc: 0.2659 - val_loss: 1.5594 - val_acc: 0.5661\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 1.8317 - acc: 0.4537 - val_loss: 1.2437 - val_acc: 0.6526\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 1.5340 - acc: 0.5524 - val_loss: 1.0930 - val_acc: 0.6908\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 1.3697 - acc: 0.6089 - val_loss: 1.0420 - val_acc: 0.6975\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 1.2228 - acc: 0.6491 - val_loss: 0.9681 - val_acc: 0.7247\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 1.1147 - acc: 0.6824 - val_loss: 0.9847 - val_acc: 0.7310\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 1.0115 - acc: 0.7111 - val_loss: 0.8901 - val_acc: 0.7516\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.9259 - acc: 0.7371 - val_loss: 0.9537 - val_acc: 0.7431\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.8421 - acc: 0.7592 - val_loss: 0.9071 - val_acc: 0.7516\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.7812 - acc: 0.7810 - val_loss: 0.9395 - val_acc: 0.7556\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.7081 - acc: 0.8061 - val_loss: 1.0101 - val_acc: 0.7420\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.6707 - acc: 0.8145 - val_loss: 0.9999 - val_acc: 0.7534\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.6158 - acc: 0.8224 - val_loss: 1.0890 - val_acc: 0.7582\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.5620 - acc: 0.8478 - val_loss: 1.0519 - val_acc: 0.7608\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 44s 5ms/step - loss: 0.5245 - acc: 0.8611 - val_loss: 1.0344 - val_acc: 0.7652\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 44s 5ms/step - loss: 0.4836 - acc: 0.8735 - val_loss: 1.1480 - val_acc: 0.7608\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.4330 - acc: 0.8831 - val_loss: 1.1994 - val_acc: 0.7652\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.4211 - acc: 0.8868 - val_loss: 1.2108 - val_acc: 0.7615\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.3895 - acc: 0.8979 - val_loss: 1.1992 - val_acc: 0.7670\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.3480 - acc: 0.9079 - val_loss: 1.2632 - val_acc: 0.7637\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.3286 - acc: 0.9184 - val_loss: 1.3811 - val_acc: 0.7571\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.3226 - acc: 0.9160 - val_loss: 1.3500 - val_acc: 0.7670\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.3028 - acc: 0.9241 - val_loss: 1.3982 - val_acc: 0.7795\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.2701 - acc: 0.9335 - val_loss: 1.4107 - val_acc: 0.7703\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.2564 - acc: 0.9324 - val_loss: 1.4483 - val_acc: 0.7718\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.2595 - acc: 0.9325 - val_loss: 1.5108 - val_acc: 0.7633\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.2427 - acc: 0.9361 - val_loss: 1.5542 - val_acc: 0.7681\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.2479 - acc: 0.9395 - val_loss: 1.4694 - val_acc: 0.7663\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1993 - acc: 0.9490 - val_loss: 1.6068 - val_acc: 0.7663\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.2127 - acc: 0.9435 - val_loss: 1.6657 - val_acc: 0.7615\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.2038 - acc: 0.9489 - val_loss: 1.5910 - val_acc: 0.7678\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1965 - acc: 0.9493 - val_loss: 1.5788 - val_acc: 0.7718\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1918 - acc: 0.9526 - val_loss: 1.5712 - val_acc: 0.7663\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1492 - acc: 0.9645 - val_loss: 1.7447 - val_acc: 0.7593\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.2005 - acc: 0.9526 - val_loss: 1.6056 - val_acc: 0.7604\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1509 - acc: 0.9640 - val_loss: 1.7147 - val_acc: 0.7678\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1323 - acc: 0.9659 - val_loss: 1.8190 - val_acc: 0.7714\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 44s 6ms/step - loss: 0.1556 - acc: 0.9606 - val_loss: 1.7624 - val_acc: 0.7681\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1531 - acc: 0.9619 - val_loss: 1.6663 - val_acc: 0.7622\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.1445 - acc: 0.9665 - val_loss: 1.7345 - val_acc: 0.7608\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.1542 - acc: 0.9649 - val_loss: 1.6658 - val_acc: 0.7766\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1417 - acc: 0.9669 - val_loss: 1.7210 - val_acc: 0.7685\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1262 - acc: 0.9718 - val_loss: 1.8175 - val_acc: 0.7736\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1085 - acc: 0.9738 - val_loss: 1.7390 - val_acc: 0.7762\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.1144 - acc: 0.9712 - val_loss: 1.8202 - val_acc: 0.7711\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1212 - acc: 0.9704 - val_loss: 1.9996 - val_acc: 0.7711\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1125 - acc: 0.9742 - val_loss: 1.7670 - val_acc: 0.7788\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.1241 - acc: 0.9699 - val_loss: 1.7217 - val_acc: 0.7685\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1266 - acc: 0.9698 - val_loss: 1.8540 - val_acc: 0.7678\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.1224 - acc: 0.9709 - val_loss: 1.7654 - val_acc: 0.7803\n"
     ]
    }
   ],
   "source": [
    "train_X, train_ancestor, train_dep, train_y = _shuffle(x_train_seq, \n",
    "                                                       train_mut_ancestors_list,\n",
    "                                                       train_dep_list,\n",
    "                                                       train_label)\n",
    "model, history = train_BiLSTM(train_X, train_ancestor, train_dep, train_y, \n",
    "                     x_test_seq, test_mut_ancestors_list, test_dep_list, test_label,\n",
    "                     embedding_matrix,\n",
    "                     max_length,\n",
    "                     len(word_index)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "plt.plot(train_acc, label=\"train acc\")\n",
    "plt.plot(val_acc, label=\"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [np.where(r==1)[0][0] for r in test_label ]\n",
    "\n",
    "# model_name = ['models/BiLSTM_0817.hdf5','models/BiLSTM_08175.hdf5',\n",
    "#               'models/BiLSTM_0820.hdf5','models/BiLSTM_0821.hdf5']\n",
    "\n",
    "# model1 = load_model(model_name[0])\n",
    "# prediction1 = model1.predict([x_test_seq], batch_size=1000)\n",
    "# model2 = load_model(model_name[1])\n",
    "# prediction2 = model2.predict([x_test_seq,test_mut_ancestors_list,test_dep_list], batch_size=1000)\n",
    "# model3 = load_model(model_name[2])\n",
    "# prediction3 = model3.predict([x_test_seq,test_mut_ancestors_list,test_dep_list], batch_size=1000)\n",
    "# model4 = load_model(model_name[3])\n",
    "# prediction4 = model4.predict([x_test_seq,test_mut_ancestors_list], batch_size=1000)\n",
    "\n",
    "# model = load_model(\"./models/BiLSTM_3.hdf5\")\n",
    "prediction = model.predict([x_test_seq,test_mut_ancestors_list,test_dep_list], batch_size=1000)\n",
    "\n",
    "\n",
    "# prediction_list = []\n",
    "# for path in model_name:\n",
    "#     model = load_model(path)\n",
    "#     prediction = model.predict([x_test_seq,test_mut_ancestors_list,test_dep_list], batch_size=1000)\n",
    "#     prediction_list.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_total = prediction1 + prediction2 + prediction3 + prediction4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7802723592197276\n"
     ]
    }
   ],
   "source": [
    "pred_y = np.argmax(prediction,axis=1)\n",
    "print(\"accuracy:\",accuracy_score(pred_y.tolist(), y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LabelsMapping_inv =  {v: k for k, v in LabelsMapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = [LabelsMapping_inv[v] for v in pred_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = list(range(8001,8001+len(pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"proposed_answers.txt\", \"w\") as f:\n",
    "    for i in range(len(test_id)):\n",
    "        f.write(str(test_id[i])+\"\\t\"+pred_y[i])\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_name = ['models/BiLSTM_0817.hdf5','models/BiLSTM_08175.hdf5',\n",
    "#               'models/BiLSTM_0820.hdf5','models/BiLSTM_0821.hdf5']\n",
    "\n",
    "Micro-averaged result (excluding Other):\n",
    "P = 1956/2367 =  82.64%     R = 1956/2263 =  86.43%     F1 =  84.49%\n",
    "\n",
    "MACRO-averaged result (excluding Other):\n",
    "P =  82.12%     R =  85.90%     F1 =  83.89%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
